{
  "error": {
    "message": "404 No models loaded. Please load a model in the developer page or use the `lms load` command.",
    "stack": "Error: 404 No models loaded. Please load a model in the developer page or use the `lms load` command.\n    at APIError.generate (file:///home/atmandk/LowCal-dev/node_modules/openai/core/error.mjs:50:20)\n    at OpenAI.makeStatusError (file:///home/atmandk/LowCal-dev/node_modules/openai/client.mjs:156:32)\n    at OpenAI.makeRequest (file:///home/atmandk/LowCal-dev/node_modules/openai/client.mjs:301:30)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async file:///home/atmandk/LowCal-dev/packages/core/dist/src/core/openaiContentGenerator/pipeline.js:21:37\n    at async ContentGenerationPipeline.executeWithErrorHandling (file:///home/atmandk/LowCal-dev/packages/core/dist/src/core/openaiContentGenerator/pipeline.js:203:28)\n    at async retryWithBackoff (file:///home/atmandk/LowCal-dev/packages/core/dist/src/utils/retry.js:121:20)\n    at async GeminiClient.generateContent (file:///home/atmandk/LowCal-dev/packages/core/dist/src/core/client.js:815:28)"
  },
  "context": {
    "requestContents": [
      {
        "role": "user",
        "parts": [
          {
            "text": "Say hello."
          }
        ]
      }
    ],
    "requestConfig": {
      "temperature": 0,
      "topP": 1
    }
  }
}